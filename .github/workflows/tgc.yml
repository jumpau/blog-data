name: TC

on:
  schedule:
    - cron: '0 */1 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: self-hosted

    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: 18
        cache: 'yarn'
        
    - uses: awalsh128/cache-apt-pkgs-action@latest
      with:
        packages: ffmpeg chromium-browser
        version: 1.0

    - name: Create and activate venv, install dependencies
      run: |
        set -xe
        python3 -m venv venv
        source venv/bin/activate
        python3 -VV
        pip install telethon
        pip install --upgrade pip
        pip install git+https://github.com/jumpau/TBCCG.git
        yarn global add puppeteer-lottie-cli

    - name: Setup working directory
      run: |
        ls -lah
        echo "Working in main branch, files will be kept locally"
    
    - name: Run tgc
      env:
        tgc_config: ${{ secrets.TGC_CONFIG }}
        PYTHONUNBUFFERED: 1
      run: |
        source venv/bin/activate
        tgc
    
    - name: Zotero Download
      env:
        ZOTERO: ${{ secrets.ZOTERO_USERID }}
      if: "${{ env.ZOTERO != '' }}"
      run: |
        rm -rf zotero.json
        curl -L "https://api.zotero.org/users/${ZOTERO}/publications/items?linkwrap=1&order=date&sort=desc&start=0&include=data&limit=100" --output zotero.json
        ls -lah
        
    - name: Profile Readme Download
      env:
        REPO_NAME: ${{ github.repository }}
      run: |
        echo "$REPO_NAME"
        USER=$(python3 -c "print('${REPO_NAME}'.split('/')[0])")
        echo "$USER"
        rm -rf profile-readme.md
        if ! curl -L "https://raw.githubusercontent.com/${USER}/${USER}/main/README.md" --output profile-readme.md; then
          echo "Failed to download readme."
        fi
        ls -lah
        
    - name: List generated files
      run: |
        echo "Generated files are kept in the current directory:"
        ls -lah
        
    - name: Backup generated files locally
      run: |
        # 创建本地备份目录
        mkdir -p ~/blog-backup/$(date +%Y%m%d_%H%M%S)
        BACKUP_DIR=~/blog-backup/$(date +%Y%m%d_%H%M%S)
        
        # 复制生成的文件到备份目录
        if [ -f atom.xml ]; then cp atom.xml $BACKUP_DIR/; fi
        if [ -f index.html ]; then cp index.html $BACKUP_DIR/; fi
        if [ -f posts.json ]; then cp posts.json $BACKUP_DIR/; fi
        if [ -f rss.xml ]; then cp rss.xml $BACKUP_DIR/; fi
        
        echo "Files backed up to: $BACKUP_DIR"
        ls -lah $BACKUP_DIR
        
    - name: Deploy to Cloudflare Pages
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        CLOUDFLARE_PROJECT_NAME: ${{ secrets.CLOUDFLARE_PROJECT_NAME }}
      run: |
        # 安装 wrangler CLI
        npm install -g wrangler
        
        # 创建部署目录
        mkdir -p deploy
        
        # 复制要部署的文件
        if [ -f atom.xml ]; then cp atom.xml deploy/; fi
        if [ -f index.html ]; then cp index.html deploy/; fi
        if [ -f posts.json ]; then cp posts.json deploy/; fi
        if [ -f rss.xml ]; then cp rss.xml deploy/; fi
        
        # 部署到 Cloudflare Pages
        cd deploy
        wrangler pages deploy . --project-name=$CLOUDFLARE_PROJECT_NAME
        
        echo "Deployment completed!"
