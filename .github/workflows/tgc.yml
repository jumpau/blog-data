name: TC

on:
  schedule:
    - cron: '0 */1 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: self-hosted

    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: 18
        cache: 'yarn'
        
    - uses: awalsh128/cache-apt-pkgs-action@latest
      with:
        packages: ffmpeg chromium-browser
        version: 1.0

    - name: Create and activate venv, install dependencies
      run: |
        set -xe
        python3 -m venv venv
        source venv/bin/activate
        python3 -VV
        pip install telethon
        pip install --upgrade pip
        pip install git+https://github.com/jumpau/TBCCG.git
        yarn global add puppeteer-lottie-cli

    - name: Setup working directory
      run: |
        ls -lah
        echo "Working in main branch, files will be kept locally"
    
    - name: Run tgc
      env:
        tgc_config: ${{ secrets.TGC_CONFIG }}
        PYTHONUNBUFFERED: 1
      run: |
        source venv/bin/activate
        tgc
    
    - name: Zotero Download
      env:
        ZOTERO: ${{ secrets.ZOTERO_USERID }}
      if: "${{ env.ZOTERO != '' }}"
      run: |
        rm -rf zotero.json
        curl -L "https://api.zotero.org/users/${ZOTERO}/publications/items?linkwrap=1&order=date&sort=desc&start=0&include=data&limit=100" --output zotero.json
        ls -lah
        
    - name: Profile Readme Download
      env:
        REPO_NAME: ${{ github.repository }}
      run: |
        echo "$REPO_NAME"
        USER=$(python3 -c "print('${REPO_NAME}'.split('/')[0])")
        echo "$USER"
        rm -rf profile-readme.md
        if ! curl -L "https://raw.githubusercontent.com/${USER}/${USER}/main/README.md" --output profile-readme.md; then
          echo "Failed to download readme."
        fi
        ls -lah
        
    - name: List generated files
      run: |
        echo "Generated files are kept in the current directory:"
        ls -lah
        
    - name: Backup generated files locally
      run: |
        # åˆ›å»ºæœ¬åœ°å¤‡ä»½ç›®å½•
        mkdir -p ~/blog-backup/$(date +%Y%m%d_%H%M%S)
        BACKUP_DIR=~/blog-backup/$(date +%Y%m%d_%H%M%S)
        
        # å¤åˆ¶ç”Ÿæˆçš„æ–‡ä»¶åˆ°å¤‡ä»½ç›®å½•
        if [ -f atom.xml ]; then cp atom.xml $BACKUP_DIR/; fi
        if [ -f index.html ]; then cp index.html $BACKUP_DIR/; fi
        if [ -f posts.json ]; then cp posts.json $BACKUP_DIR/; fi
        if [ -f rss.xml ]; then cp rss.xml $BACKUP_DIR/; fi
        
        echo "Files backed up to: $BACKUP_DIR"
        ls -lah $BACKUP_DIR
        
    - name: Deploy to Cloudflare Pages
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        CLOUDFLARE_PROJECT_NAME: ${{ secrets.CLOUDFLARE_PROJECT_NAME }}
        tgc_config: ${{ secrets.TGC_CONFIG }}
      run: |
        # å®‰è£… toml è§£æåº“
        source venv/bin/activate
        pip install toml
        
        # ä½¿ç”¨Pythonè„šæœ¬æ¥è§£æé…ç½®å¹¶éƒ¨ç½²
        cat > deploy_script.py << 'EOF'
        import os
        import toml
        import json
        import shutil
        import subprocess
        from pathlib import Path
        
        # è§£æTGCé…ç½®
        config_str = os.environ.get('tgc_config', '')
        if not config_str:
            print("âŒ TGC_CONFIG ä¸ºç©º")
            exit(1)
        
        # å†™å…¥ä¸´æ—¶é…ç½®æ–‡ä»¶
        with open('temp_config.toml', 'w', encoding='utf-8') as f:
            f.write(config_str)
        
        try:
            config = toml.load('temp_config.toml')
            source_dir = ""
            if 'exports' in config and len(config['exports']) > 0:
                source_dir = config['exports'][0].get('path', '')
        except Exception as e:
            print(f"âŒ è§£æé…ç½®å¤±è´¥: {e}")
            source_dir = ""
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists('temp_config.toml'):
            os.remove('temp_config.toml')
        
        if not source_dir:
            print("âŒ æ— æ³•ä»é…ç½®ä¸­è·å–è¾“å‡ºè·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
            source_dir = "../../../../../../../www/wwwroot/bk.cn"
        
        print(f"ğŸ“ ä½¿ç”¨è¾“å‡ºç›®å½•: {source_dir}")
        
        # åˆ›å»ºéƒ¨ç½²ç›®å½•
        deploy_dir = Path('deploy')
        deploy_dir.mkdir(exist_ok=True)
        
        # è¦å¤åˆ¶çš„æ–‡ä»¶åˆ—è¡¨
        files_to_copy = ['atom.xml', 'index.html', 'posts.json', 'rss.xml']
        copied_files = []
        
        # å¤åˆ¶æ–‡ä»¶
        source_path = Path(source_dir)
        print(f"=== æ£€æŸ¥æºç›®å½•: {source_path.absolute()} ===")
        
        if source_path.exists():
            print("âœ“ æºç›®å½•å­˜åœ¨")
            for file_name in files_to_copy:
                src_file = source_path / file_name
                dst_file = deploy_dir / file_name
                if src_file.exists():
                    shutil.copy2(src_file, dst_file)
                    print(f"âœ“ å¤åˆ¶äº† {file_name}")
                    copied_files.append(file_name)
                else:
                    print(f"âœ— {file_name} ä¸å­˜åœ¨")
        else:
            print("âŒ æºç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾æ–‡ä»¶...")
            # æŸ¥æ‰¾æ–‡ä»¶
            for root, dirs, files in os.walk('.'):
                for file_name in files_to_copy:
                    if file_name in files:
                        src_file = Path(root) / file_name
                        dst_file = deploy_dir / file_name
                        shutil.copy2(src_file, dst_file)
                        print(f"âœ“ æ‰¾åˆ°å¹¶å¤åˆ¶äº† {file_name} ä» {src_file}")
                        copied_files.append(file_name)
        
        print(f"=== éƒ¨ç½²ç›®å½•æ–‡ä»¶åˆ—è¡¨ ===")
        for item in deploy_dir.iterdir():
            if item.is_file():
                print(f"{item.name} ({item.stat().st_size} bytes)")
        
        if not copied_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶å¯ä»¥éƒ¨ç½²ï¼")
            exit(1)
        
        print(f"âœ… å‡†å¤‡éƒ¨ç½² {len(copied_files)} ä¸ªæ–‡ä»¶: {', '.join(copied_files)}")
        EOF
        
        # è¿è¡Œéƒ¨ç½²è„šæœ¬
        python3 deploy_script.py
        
        # å¦‚æœæœ‰æ–‡ä»¶è¢«å¤åˆ¶ï¼Œåˆ™åˆ›å»ºä¸Šä¼ è„šæœ¬
        if [ -d "deploy" ] && [ "$(ls -A deploy)" ]; then
          echo "=== åˆ›å»ºå¹¶è¿è¡Œä¸Šä¼ è„šæœ¬ ==="
          
          # å®‰è£…ä¾èµ–
          npm install form-data
          
          # åˆ›å»ºç®€åŒ–çš„ä¸Šä¼ è„šæœ¬
          cat > upload.js << 'EOF'
        const fs = require('fs');
        const path = require('path');
        const https = require('https');
        const FormData = require('form-data');
        
        const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
        const projectName = process.env.CLOUDFLARE_PROJECT_NAME;
        const apiToken = process.env.CLOUDFLARE_API_TOKEN;
        
        function uploadToPages() {
          return new Promise((resolve, reject) => {
            const form = new FormData();
            const manifest = {};
            const deployDir = 'deploy';
            
            const files = fs.readdirSync(deployDir);
            console.log('ä¸Šä¼ æ–‡ä»¶:', files);
            
            files.forEach(file => {
              const filePath = path.join(deployDir, file);
              const stats = fs.statSync(filePath);
              const hash = require('crypto').createHash('sha1').update(fs.readFileSync(filePath)).digest('hex');
              
              manifest[`/${file}`] = { hash, size: stats.size };
              form.append('file', fs.createReadStream(filePath), { filename: file, filepath: `/${file}` });
            });
            
            form.append('manifest', JSON.stringify(manifest));
            
            const options = {
              hostname: 'api.cloudflare.com',
              path: `/client/v4/accounts/${accountId}/pages/projects/${projectName}/deployments`,
              method: 'POST',
              headers: { 'Authorization': `Bearer ${apiToken}`, ...form.getHeaders() }
            };
            
            const req = https.request(options, (res) => {
              let data = '';
              res.on('data', chunk => data += chunk);
              res.on('end', () => {
                console.log('Status:', res.statusCode);
                if (res.statusCode === 200 || res.statusCode === 201) {
                  console.log('âœ… éƒ¨ç½²æˆåŠŸ!');
                  resolve(data);
                } else {
                  console.error('âŒ éƒ¨ç½²å¤±è´¥:', res.statusCode, data);
                  reject(new Error(`Deploy failed: ${res.statusCode}`));
                }
              });
            });
            
            req.on('error', reject);
            form.pipe(req);
          });
        }
        
        uploadToPages().catch(console.error);
        EOF
          
          # è¿è¡Œä¸Šä¼ 
          node upload.js
        else
          echo "âŒ æ²¡æœ‰æ–‡ä»¶å¯ä»¥éƒ¨ç½²"
        fi
