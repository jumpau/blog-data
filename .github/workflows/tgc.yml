name: TC

on:
  schedule:
    - cron: '0 */1 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: self-hosted

    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: 18
        cache: 'yarn'
        
    - uses: awalsh128/cache-apt-pkgs-action@latest
      with:
        packages: ffmpeg chromium-browser
        version: 1.0

    - name: Create and activate venv, install dependencies
      run: |
        set -xe
        python3 -m venv venv
        source venv/bin/activate
        python3 -VV
        pip install telethon
        pip install --upgrade pip
        pip install git+https://github.com/jumpau/TBCCG.git
        yarn global add puppeteer-lottie-cli

    - name: Setup working directory
      run: |
        ls -lah
        echo "Working in main branch, files will be kept locally"
    
    - name: Run tgc
      env:
        tgc_config: ${{ secrets.TGC_CONFIG }}
        PYTHONUNBUFFERED: 1
      run: |
        source venv/bin/activate
        tgc
    
    - name: Zotero Download
      env:
        ZOTERO: ${{ secrets.ZOTERO_USERID }}
      if: "${{ env.ZOTERO != '' }}"
      run: |
        rm -rf zotero.json
        curl -L "https://api.zotero.org/users/${ZOTERO}/publications/items?linkwrap=1&order=date&sort=desc&start=0&include=data&limit=100" --output zotero.json
        ls -lah
        
    - name: Profile Readme Download
      env:
        REPO_NAME: ${{ github.repository }}
      run: |
        echo "$REPO_NAME"
        USER=$(python3 -c "print('${REPO_NAME}'.split('/')[0])")
        echo "$USER"
        rm -rf profile-readme.md
        if ! curl -L "https://raw.githubusercontent.com/${USER}/${USER}/main/README.md" --output profile-readme.md; then
          echo "Failed to download readme."
        fi
        ls -lah
        
    - name: List generated files
      run: |
        echo "Generated files are kept in the current directory:"
        ls -lah
        
    - name: Backup generated files locally
      run: |
        # 创建本地备份目录
        mkdir -p ~/blog-backup/$(date +%Y%m%d_%H%M%S)
        BACKUP_DIR=~/blog-backup/$(date +%Y%m%d_%H%M%S)
        
        # 复制生成的文件到备份目录
        if [ -f atom.xml ]; then cp atom.xml $BACKUP_DIR/; fi
        if [ -f index.html ]; then cp index.html $BACKUP_DIR/; fi
        if [ -f posts.json ]; then cp posts.json $BACKUP_DIR/; fi
        if [ -f rss.xml ]; then cp rss.xml $BACKUP_DIR/; fi
        
        echo "Files backed up to: $BACKUP_DIR"
        ls -lah $BACKUP_DIR
        
    - name: Deploy to Cloudflare Pages
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        CLOUDFLARE_PROJECT_NAME: ${{ secrets.CLOUDFLARE_PROJECT_NAME }}
      run: |
        # 安装必要的依赖
        npm install undici
        
        # 创建部署目录
        mkdir -p assets
        
        # 复制要部署的文件
        if [ -f atom.xml ]; then cp atom.xml assets/; fi
        if [ -f index.html ]; then cp index.html assets/; fi
        if [ -f posts.json ]; then cp posts.json assets/; fi
        if [ -f rss.xml ]; then cp rss.xml assets/; fi
        
        # 创建上传脚本
        cat > upload.mjs << 'EOF'
        import * as fs from "fs";
        import * as path from "path";
        import * as crypto from "crypto";
        import { FormData, fetch } from "undici";
        import "node:process";

        const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
        const filesDirectory = "assets";
        const scriptName = process.env.CLOUDFLARE_PROJECT_NAME;
        const dispatchNamespace = "";

        function calculateFileHash(filePath) {
          const hash = crypto.createHash("sha256");
          const fileBuffer = fs.readFileSync(filePath);
          hash.update(fileBuffer);
          const fileHash = hash.digest("hex").slice(0, 32);
          const fileSize = fileBuffer.length;
          return { fileHash, fileSize };
        }

        function gatherFileMetadata(directory) {
          const files = fs.readdirSync(directory);
          const fileMetadata = {};

          files.forEach((file) => {
            const filePath = path.join(directory, file);
            const { fileHash, fileSize } = calculateFileHash(filePath);
            fileMetadata["/" + file] = {
              hash: fileHash,
              size: fileSize,
            };
          });

          return fileMetadata;
        }

        function findMatch(fileHash, fileMetadata) {
          for (let prop in fileMetadata) {
            const file = fileMetadata[prop];
            if (file.hash === fileHash) {
              return prop;
            }
          }
          throw new Error("unknown fileHash");
        }

        async function uploadFilesBatch(jwt, fileHashes, fileMetadata) {
          const form = new FormData();

          for (const bucket of fileHashes) {
            bucket.forEach((fileHash) => {
              const fullPath = findMatch(fileHash, fileMetadata);
              const relPath = filesDirectory + "/" + path.basename(fullPath);
              const fileBuffer = fs.readFileSync(relPath);
              const base64Data = fileBuffer.toString("base64");

              form.append(
                fileHash,
                new File([base64Data], fileHash, {
                  type: "text/html",
                }),
                fileHash,
              );
            });

            const response = await fetch(
              `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/assets/upload?base64=true`,
              {
                method: "POST",
                headers: {
                  Authorization: `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
                },
                body: form,
              },
            );

            const data = await response.json();
            if (data && data.result.jwt) {
              return data.result.jwt;
            }
          }

          throw new Error("Should have received completion token");
        }

        async function scriptUpload(completionToken) {
          const form = new FormData();

          form.append(
            "metadata",
            JSON.stringify({
              main_module: "index.mjs",
              compatibility_date: "2022-03-11",
              assets: {
                jwt: completionToken,
              },
              bindings: [{ name: "ASSETS", type: "assets" }],
            }),
          );

          form.append(
            "index.js",
            new File(
              [
                "export default {async fetch(request, env) { return env.ASSETS.fetch(request); }}",
              ],
              "index.mjs",
              {
                type: "application/javascript+module",
              },
            ),
          );

          const url = dispatchNamespace
            ? `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/dispatch/namespaces/${dispatchNamespace}/scripts/${scriptName}`
            : `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${scriptName}`;

          const response = await fetch(url, {
            method: "PUT",
            headers: {
              Authorization: `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
            },
            body: form,
          });

          if (response.status != 200) {
            const errorText = await response.text();
            throw new Error(`Unexpected status code: ${response.status}, Response: ${errorText}`);
          }
        }

        async function startUploadSession() {
          const fileMetadata = gatherFileMetadata(filesDirectory);

          const requestBody = JSON.stringify({
            manifest: fileMetadata,
          });

          const url = dispatchNamespace
            ? `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/dispatch/namespaces/${dispatchNamespace}/scripts/${scriptName}/assets-upload-session`
            : `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/scripts/${scriptName}/assets-upload-session`;

          const response = await fetch(url, {
            method: "POST",
            headers: {
              Authorization: `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
              "Content-Type": "application/json",
            },
            body: requestBody,
          });

          const data = await response.json();
          const jwt = data.result.jwt;

          return {
            uploadToken: jwt,
            buckets: data.result.buckets,
            fileMetadata,
          };
        }

        const { uploadToken, buckets, fileMetadata } = await startUploadSession();
        let completionToken = uploadToken;
        if (buckets.length > 0) {
          completionToken = await uploadFilesBatch(uploadToken, buckets, fileMetadata);
        }
        await scriptUpload(completionToken);
        console.log("Deployment completed!");
        EOF
        
        # 运行上传脚本
        node upload.mjs
        
        echo "Files deployed to Cloudflare Workers!"
